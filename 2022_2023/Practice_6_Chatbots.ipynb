{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorenoLaQuatra/DeepNLP/blob/main/practices/P7/Practice_7_Chatbots.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq3YM-Q5SwNn"
      },
      "source": [
        "# **Deep Natural Language Processing @ PoliTO**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Teaching Assistant:** Moreno La Quatra\n",
        "\n",
        "**Practice 7:** Chatbots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhUhU368S2Y-"
      },
      "source": [
        "# Simple chatbot architecture using RASA \n",
        "\n",
        "Chatbots can be defined as a computer program that simulates a conversation with a human user. They are used in a wide range of applications, from customer service to e-commerce. In this practice, we will explore the RASA framework and build a simple chatbot that can answer to some questions in specific domains.\n",
        "\n",
        "The goal of the practice is to explore the usage of intents, stories and domain definitions to add specific properties to our chatbot.\n",
        "\n",
        "The following cells install the RASA framework and set up the environment to start working on the practice. Please run them before starting the practice and restart the runtime when asked (there is a comment in the cell indicating when to restart)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_FQKauLS2FE"
      },
      "outputs": [],
      "source": [
        "! pip install --upgrade pip==20.2\n",
        "! pip install ipython\n",
        "! pip install nest_asyncio\n",
        "! pip install tensoflow <= 2.4\n",
        "! pip install -U rasa\n",
        "! pip install awscli --ignore-installed six"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBfiTzLeSn1p"
      },
      "outputs": [],
      "source": [
        "!pip install -U ipython\n",
        "# restart runtime: Runtime -> Restart runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTiOyCEYTD8Z"
      },
      "source": [
        "## Question 1: First steps with rasa chatbots\n",
        "\n",
        "Before diving into the practice, let's see how to use the RASA framework to build a simple chatbot. Use the simple chatbot example provided in the RASA documentation to build the simplest chatbot possible. The following cells will guide you through the process and let you test the chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZPM-_lwTK-l"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import os\n",
        "import rasa\n",
        "import nest_asyncio\n",
        "from rasa.cli.scaffold import create_initial_project\n",
        "\n",
        "nest_asyncio.apply()\n",
        "print(\"Event loop ready.\")\n",
        "\n",
        "project = \"my-chatbot\"\n",
        "create_initial_project(project)\n",
        "os.chdir(project)\n",
        "\n",
        "config = \"config.yml\"\n",
        "training_files = \"data/\"\n",
        "domain = \"domain.yml\"\n",
        "output = \"models/\"\n",
        "print(config, training_files, domain, output)\n",
        "\n",
        "model_path = rasa.train(domain, config, [training_files], output)\n",
        "model_path = model_path.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnUsn5jlTbNn"
      },
      "outputs": [],
      "source": [
        "from rasa.jupyter import chat\n",
        "\n",
        "endpoints = \"endpoints.yml\"\n",
        "chat(model_path, endpoints)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4Tys9K2TKfS"
      },
      "source": [
        "## Question 2: your own chatbot\n",
        "\n",
        "RASA chatbots exploit the following files to recognize intents and take the corresponding actions:\n",
        "\n",
        "- `/data/nlu.yml`: contains the set of intents that are used by the chatbot for recognizing user request. This file contains examples that are used to generate examples to train the chatbot. NLU in [RASA doc](https://rasa.com/docs/rasa/training-data-format/#nlu-training-data).\n",
        "\n",
        "- `stories.yml`: this file contains the examples of interactions between the chatbot and the user. They define possible path of the conversation with corresponding chatbot actions, responses for each user input. Stories in [RASA doc](https://rasa.com/docs/rasa/stories).\n",
        "\n",
        "- `domain.yml`: according to the official documentation: `The domain defines the universe in which your assistant operates. It specifies the intents, entities, slots, responses, forms, and actions your bot should know about.` This file contains a list of information that your chatbot need to know to operate. Domain in [RASA doc](https://rasa.com/docs/rasa/domain/).\n",
        "\n",
        "\n",
        "Modify the base chatbot to recognize one or multiple new intents (e.g., user looking for the weather). \n",
        "\n",
        "Re-run training and demo of Q1 to qualitetively evaluate your changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPJSNzx1W-2f"
      },
      "outputs": [],
      "source": [
        "# Your code here (you need to modify files in the file explorer section)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEEoqRyXbIaB"
      },
      "source": [
        "# Create a chatbot using transformers\n",
        "\n",
        "RASA is a powerful framework that allows to build chatbots with a wide range of functionalities. It can relies on external models for the the generation of new responses. In this section, we will use the transformers library to create a chatbot that can generate responses to user requests.\n",
        "\n",
        "![](https://huggingface.co/front/thumbnails/dialogpt.png)\n",
        "\n",
        "On the other side, [Huggingface pipelines module](https://huggingface.co/docs/transformers/master/en/main_classes/pipelines) offers an easy interface to use pre-trained models. In particular, we will use the `pipeline` function to create a chatbot that can generate responses to user requests (e.g., DialoGPT). The conversational pipeline allows the implementation of a simple chatbot with carry-on conversations. It exploit the DialoGPT models available on the model hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpFpFIFHb6mN"
      },
      "source": [
        "## **Question 3: DialoGPT single answer**\n",
        "\n",
        "Create a conversational pipeline. Write a function that takes as input a user request and returns the generated response. Test your chatbot with different text prompts simulating real conversations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ro3KIC2JW4Dc"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "\n",
        "def conversation_function():\n",
        "    # Your code here\n",
        "    pass\n",
        "\n",
        "user_prompt = input(\"Your message: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ytWSQJq7dfr"
      },
      "source": [
        "## **Question 4: Conversations**\n",
        "\n",
        "Extend the previous function to generate a conversation with DialoGPT. Choose a stop sequence that let the user end the conversation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2BnAufo7c5y"
      },
      "outputs": [],
      "source": [
        "# Your code here\n",
        "\n",
        "STOP_SEQUENCE = \"STOP\"\n",
        "\n",
        "def conversation_function(pipeline):\n",
        "    # Your code here\n",
        "    while text != STOP_SEQUENCE:\n",
        "        # Your code here\n",
        "\n",
        "conversation_function(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUNapmc47r-J"
      },
      "source": [
        "### **Question 5: Artificial conversations** \n",
        "\n",
        "Bots are created to engage conversations with a human user. However, we can simulate a conversation between two bots. In this question, we will create a chatbot that can simulate a conversation with DialoGPT.\n",
        "\n",
        "Create another instance of the pipeline that uses another model for the chatbot (e.g., [`satvikag/chatbot`](https://huggingface.co/satvikag/chatbot)). Use the two instances to create a conversation between two bots.\n",
        "\n",
        "Note: to startup conversation insert an user input of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmPmZdnrXLUU"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvfkg1rn96Ay"
      },
      "source": [
        "### **Question 6: Improving interaction** \n",
        "\n",
        "The conversations in the previous questions shows very limited variability. Create a new function to manually conversate with DialoGPT model by setting different parameters (e.g., [beam search](https://en.wikipedia.org/wiki/Beam_search) is disabled by default). To do so instantiate a new [DialoGPT model](https://huggingface.co/microsoft/DialoGPT-medium), it inherits from the `AutoModelForCausalLM`. \n",
        "\n",
        "Here a simple blog post that shows how to use different decoding strategies with DialoGPT: [https://huggingface.co/blog/how-to-generate](https://huggingface.co/blog/how-to-generate).\n",
        "\n",
        "Note: Basic examples on how to use the model are provided [here](https://huggingface.co/microsoft/DialoGPT-medium#how-to-use).\n",
        "\n",
        "Note 2: Take some time to explore the input for the [generate](https://huggingface.co/docs/transformers/main/en/main_classes/text_generation#transformers.GenerationMixin.generate) function. Hereafter some examples of relevant parameters.\n",
        "```\n",
        "num_beams (int, optional, defaults to 1) — Number of beams for beam search. 1 means no beam search.\n",
        "temperature (float, optional, defaults to 1.0) — The value used to module the next token probabilities.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9iIvc77XNFs"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAPl82lLOWwO"
      },
      "source": [
        "### **Question 6: Artificial conversations pt.2** \n",
        "\n",
        "Choose your preferred parameters' configuration obtained at Q5. Let the model chat with himself (similarly to Q3). How is the interaction?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtjO_W5-XQC8"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPA6deu7phkH4O2t8PVJpCH",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Practice 7 - Chatbots.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
