{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 1 - Text processing and topic modelling",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZIl1U-b7AzU"
      },
      "source": [
        "**Deep Natural Language Processing @ PoliTO**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Teaching Assistant:** Moreno La Quatra\n",
        "\n",
        "**Practice 1:** Text processing and topic modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1vQPzjM9r8c"
      },
      "source": [
        "# **Text processing**\n",
        "\n",
        "The text processing phase is a preliminary stage where the text to be manipulated is processed to be ready for subsequent analysis.\n",
        "\n",
        "Text processing usually entails several steps that could possibly include:\n",
        "- **Language Identification**: identifying the language of a given text.\n",
        "- **Tokenization**: splitting a given text in several sentences/words. \n",
        "- **Dependency tree parsing:** analyzing the depencies between words composing the text.\n",
        "- **Stemming/Lemmatization:** obtain the root form for each word in text.\n",
        "- **Stopword removal**: removing words that are si commonly used that they carry very little useful information.\n",
        "- **Part of Speech Tagging:** given a word, retrieve its part of speech (proper noun, common noun or verb).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2dHRmrPB22r"
      },
      "source": [
        "### Language Identification\n",
        "\n",
        "| Text                                                                                                                                | Language Code |\n",
        "|-------------------------------------------------------------------------------------------------------------------------------------|---------------|\n",
        "| The \"Deep Natural Language Processing\" course is offered during the first semester of the second year at Politecnico di Torino      | `EN`            |\n",
        "| Il corso \"Deep Natural Language Processing\" viene impartito al Politecnico di Torino durante il primo semestre del secondo anno.    | `IT`            |\n",
        "| Le cours \"Deep Natural Language Processing\" est enseigné au Politecnico di Torino pendant le premier semestre de la deuxième année. | `FR`            |\n",
        "\n",
        "**Language Identification** is a crucial prelimiary step because each language has its own characteristics. The knowledge of the main language associated to a given text could be beneficial for all subsequent steps in text processing pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ej_dfjm2srd"
      },
      "source": [
        "# Exercise 1:\n",
        "\n",
        "Benchmark different language-detection algorithm by computing the accuracy of each approach:\n",
        "- [FastText](https://pypi.org/project/fastlangid/)\n",
        "- [LangID](https://github.com/saffsd/langid.py)\n",
        "- [langdetect](https://pypi.org/project/langdetect/)\n",
        "\n",
        "The data collection used in this first part of the practice is provided [here](https://github.com/MorenoLaQuatra/DeepNLP/blob/main/practices/P1/langid_dataset.csv) - [source: Kaggle](https://www.kaggle.com/martinkk5575/language-detection)\n",
        "\n",
        "**Hint:** language code conversion: [iso639-lang](https://pypi.org/project/iso639-lang/)\n",
        "\n",
        "For each method report:\n",
        "- Accuracy\n",
        "- Average time per example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ7xbkps3_mR"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/langid_dataset.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-509xNcU0tcU"
      },
      "source": [
        "# your code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIOgOZy1ENh2"
      },
      "source": [
        "# Exercise 2\n",
        "\n",
        "For English-written text, apply word-level tokenization. What is the average number of words per sentence?\n",
        "\n",
        "Implement word-tokenization using both [nltk](https://www.nltk.org/) and [spacy](https://spacy.io/). Report the results for both of them.\n",
        "\n",
        "For spaCy use the `en_core_web_sm` model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Ph9mCx00sQ"
      },
      "source": [
        "# your code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySnw80QnIf2p"
      },
      "source": [
        "# Exercise 3\n",
        "\n",
        "Use spacy to parse the dependency tree of a **randomly selected** sentence. You can both use English sentences or your native language (if supported in [spaCy](https://spacy.io/usage/models/)). Use [displaCy](https://explosion.ai/demos/displacy) to visualize the result in the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoFgoxwJ03_c"
      },
      "source": [
        "# your code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAO1E6adVMKW"
      },
      "source": [
        "# Exercise 4\n",
        "For the same sentence selected in the previous step apply all the following steps:\n",
        "1. Lemmatization: convert each word to its root form.\n",
        "2. Stopword removal: remove language-specific stopwords.\n",
        "3. Part of Speech Tagging: for each word in the sentence display its part-of-speech.\n",
        "\n",
        "For each step, print the resulting list on the console."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4-wJHnOZnwC"
      },
      "source": [
        "# your code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL4KXiBkZrta"
      },
      "source": [
        "# **Occurrence-based text representation - TF-IDF**\n",
        "\n",
        "# Exercise 5\n",
        "Use TF-IDF to vectorize each sentence in the original data collection. You can choose your preferred implementation for TF-IDF vectorization. It is also available on [SciKit-Learn library](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7L162ayglUq"
      },
      "source": [
        "# your code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4NTwm6Qbpvx"
      },
      "source": [
        "# Exercise 6\n",
        "\n",
        "Build a supervised multi-class language detector using as features the vector obtained by TF-IDF representation. Use 80% of the data to train the language detector and 20% of the data for assessing its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1HT2roy1DQu"
      },
      "source": [
        "# your code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AHlGUHuaqjW"
      },
      "source": [
        "# **Topic Modelling**\n",
        "\n",
        "Occurrence-based representations are high-dimensional, what is the dimension of the generated TF-IDF vector representation?\n",
        "Topic modelling focuses on caturing latent topics in large document corpora.\n",
        "\n",
        "The data collection used in this second part of the practice is provided [here](https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/CovidFake_filtered.csv) - [source: Zenodo](https://zenodo.org/record/4282522#.YVdCXcbOOpd)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZbbPhC6cAO8"
      },
      "source": [
        "# Exercise 7\n",
        "\n",
        "Latent Semantic Indexing (LSI) models underlying concepts by using SVD (Singular Value Decomposition).\n",
        "\n",
        "Use [gensim](https://radimrehurek.com/gensim/) library to:\n",
        "1. Create a corpus composed of the headlines contained in the data collection.\n",
        "2. Generate a [dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html) to create a word -> id mapping (required by LSI module).\n",
        "3. Using the dictionary, preprocess the corpus to obtain the representation required for LSI model training ([documentation here](https://radimrehurek.com/gensim/models/lsimodel.html)).\n",
        "4. Inspect the top-5 topics generated by the LSI model for the analysed corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwkHsT8oft_d"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P1/CovidFake_filtered.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoJAZsw11Gih"
      },
      "source": [
        "# your code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zcmfh5UkdZm"
      },
      "source": [
        "# Exercise 8 (Optional)\n",
        "\n",
        "The top-scored words contributing to each topic (if no stopword removal is applied) are english common words (e.g., *to, for, in, of, on*..). Repeat the same procedure of Ex. 7 by adding a preliminary preprocessing step to **remove stopwords**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz2NUP6O1JAK"
      },
      "source": [
        "# your code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zssKPqSdyYgY"
      },
      "source": [
        "# Exercise 9 (Optional)\n",
        "\n",
        "Leveraging the same corpus used for LSI model generation, apply LDA modelling setting the number of topics to 5. Display the words most contributing to the those topics according to the LDA model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzCXdEUW1MHs"
      },
      "source": [
        "# your code"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}