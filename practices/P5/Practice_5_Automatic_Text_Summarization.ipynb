{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 5 - Automatic Text Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPatrAoDMtErRguxbFqqPpV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorenoLaQuatra/DeepNLP/blob/main/practices/P5/Practice_5_Automatic_Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23KZw7Xd5XhK"
      },
      "source": [
        "#**Deep Natural Language Processing @ PoliTO**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Teaching Assistant:** Moreno La Quatra\n",
        "\n",
        "**Practice 5:** Automatic Text Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlb9Te9I5exv"
      },
      "source": [
        "## Extractive Text Summarization\n",
        "\n",
        "Content is extracted from the original data, but the extracted content is not modified in any way.\n",
        "\n",
        "![](https://images.deepai.org/machine-learning-models/8f66b1eb608e4eb681b2ec0c0631385c/summarization.jpg)\n",
        "\n",
        "For this part of the practice we will use the BBC News Summary dataset available in [Kaggle](https://www.kaggle.com/pariza/bbc-news-summary)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiCTbAwGA6RK"
      },
      "source": [
        "%%capture\n",
        "! wget https://github.com/MorenoLaQuatra/DeepNLP/raw/main/practices/P5/bbc_news.zip\n",
        "! unzip bbc_news.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoJgwbjDFCAq"
      },
      "source": [
        "### **Question 1: split data collection**\n",
        "\n",
        "Read the data collection and split it into train/test/eval. Data are provided with different classes (e.g., business, sport, tech...), be sure to select 10% of data for testing **for each class**.\n",
        "\n",
        "**Note 1:** Some files can report UnicodeError, feel free to ignore it (`errors` parameter)\n",
        "\n",
        "**Note 2:** you can fix encoding after file reading by using [ftfy](https://pypi.org/project/ftfy/) library "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFw-VeeLJCS7"
      },
      "source": [
        "!pip install ftfy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1r_evLR5FBq4"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTHNVAqn1Pfg"
      },
      "source": [
        "### **Question 2: Unsupervised Text Summarization (TextRank)**\n",
        "\n",
        "[TextRank](https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf) is an unsupervised text summarization approach that relies on graph modelling. Implement a `TextrankSummarizer` class that expose the `summarize(sentences, N)` function to get the `N` most relevant sentences from a list (`sentences`). \n",
        "\n",
        "The main steps are reported here:\n",
        "\n",
        "1. Each sentence is a node in a graph (undirected)\n",
        "2. A pair of sentence is connected with an edge whose weight is computed according to the number of common words (see Note 1).\n",
        "3. Pagerank is used to compute a relevance score for each node in the graph (for each sentence in the list)\n",
        "4. The `summarize` function return the summary concatenating the `N`  most relevant sentences (according to the score computed at step 3).\n",
        "\n",
        "**Note 1:** An example of the similarity function that can be used to compute graph weights is repoted below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDzCPn0E41sJ"
      },
      "source": [
        "import math\n",
        "\n",
        "def compute_similarity(tokens_sent_1, tokens_sent_2):\n",
        "\n",
        "    n_common_words = len(set(tokens_sent_1) & set(tokens_sent_2))\n",
        "\n",
        "    log_s1 = math.log10(len(words_sentence_one))\n",
        "    log_s2 = math.log10(len(words_sentence_two))\n",
        "\n",
        "    if log_s1 + log_s2 == 0:\n",
        "        return 0\n",
        "\n",
        "    return n_common_words / (log_s1 + log_s2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vtkbqZN3XDV"
      },
      "source": [
        "'''\n",
        "# class skeleton\n",
        "\n",
        "class TextrankSummarizer:\n",
        "\n",
        "    def __init__(self):\n",
        "        continue\n",
        "   \n",
        "    def summarize(self, sentences, N=2):\n",
        "        continue\n",
        "        # TODO: implement summarization\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPD6t1G1mWKG"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wYBaG7g7Jfo"
      },
      "source": [
        "### **Question 3: Unsupervised Text Summarization (TextRank + TF-IDF)**\n",
        "\n",
        "Implement a `TextrankTFIDFSummarizer` class that expose the `summarize(sentences, N)` function to get the `N` most relevant sentences from a list (`sentences`). \n",
        "\n",
        "Implement the class similarly to Q2. This version uses a different similarity function to weigh edges connecting sentences. It uses [TF-IDF vectorization](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) and [cosine similarity](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html) to compute sentence-to-sentence similarity.\n",
        "\n",
        "- Compute TF-IDF vectors for each sentence\n",
        "- Compute edges' weights using the cosine similarity between TF-IDF vector representations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uX1XCEVmarN"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVRrBOKxCPyR"
      },
      "source": [
        "### **Question 4: Unsupervised Text Summarization (Pretrained BERT)**\n",
        "\n",
        "Both Textrank and Lexrank relies on syntactic scores to compute sentence similarity. \n",
        "Use Sentence-Transformer library to encode sentences into semantic-aware vectors and compute semantic similarity to interconnect sentences (e.g., use cosine similarity of bert encodings). Implement `BERTSummarizer` class similarly to Q2 and Q3.\n",
        "\n",
        "Note 1: use `sentence-transformers` library to obtain sentence embeddings (https://www.sbert.net/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzCUdyrkmchL"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmSnChfIFSKc"
      },
      "source": [
        "### **Question 5: ROUGE-based evaluation**\n",
        "\n",
        "Using only the **test set** obtained in Q1 compare the performance of the three summarizers implemented in Q2, Q3 and Q4. \n",
        "\n",
        "Report their results in terms of average precision, recall and F1-score for Rouge 2 metrics. Set the number of extracted sentences to 4 for all summarizers.\n",
        "\n",
        "**Which method obtain the best scores?**\n",
        "\n",
        "Note 1: You can use the python implementation of ROUGE available [here](https://pypi.org/project/rouge/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW42pxUXEhSS"
      },
      "source": [
        "! pip install rouge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dba9zCcZmfpd"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTHHcu0IIxeH"
      },
      "source": [
        "## Abstractive Text Summarization\n",
        "\n",
        "Abstractive methods build an internal semantic representation of the original content, and then use this representation to create a summary that is closer to what a human might express. Abstraction may transform the extracted content by paraphrasing sections of the source document, to condense a text more strongly than extraction. Such transformation, however, is computationally much more challenging than extraction.\n",
        "\n",
        "![https://techcommunity.microsoft.com/t5/image/serverpage/image-id/180981i9EA877DDFF97D50D?v=v2](https://techcommunity.microsoft.com/t5/image/serverpage/image-id/180981i9EA877DDFF97D50D?v=v2)\n",
        "\n",
        "Also for this part of the practice we use the BBC News Summary dataset available in [Kaggle](https://www.kaggle.com/pariza/bbc-news-summary)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQbCIzgtKIkV"
      },
      "source": [
        "### **Question 6: BART (pretrained) seq2seq model**\n",
        "\n",
        "Exploit [BART](https://huggingface.co/facebook/bart-large-cnn) pretrained on CNN Daily Mail dataset to summarize the article in the BBC test set. Compute the obtained scores in terms of average precision, recall and F1-score for Rouge 2 metrics.\n",
        "\n",
        "Note 1: for generated summaries set the maximum length to 100 and the minimum length to your preferred value.\n",
        "\n",
        "Note 2: **to speed up computation**, you can use the distilled version of the BART model (e.g., `sshleifer/distilbart-cnn-12-6` available [here](https://huggingface.co/sshleifer/distilbart-cnn-12-6))\n",
        "\n",
        "Note 3: You can use the [summarization pipeline](https://huggingface.co/transformers/main_classes/pipelines.html#transformers.SummarizationPipeline). Explictly set truncation to True to avoid index errors (e.g. `summarizer(..., truncation=True)`)\n",
        "\n",
        "Note 4: Explictly set the device to use GPU acceleration (colab runtime should be also set to GPU) while creating the pipeline object (e.g., `pipeline(..., device=0)`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FXMx1i0mlnb"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puVi1x74FfGh"
      },
      "source": [
        "### **Question 7 (bonus): Finetuning seq2seq model**\n",
        "\n",
        "Exploit the BBC dataset to finetune BART-based model on the proposed dataset. Create a fine-tuning procedure using the article text as input and the ground-truth summary as output of the model.\n",
        "\n",
        "Exploit the [Datasets framework](https://huggingface.co/docs/datasets/) and [Trainer API](https://huggingface.co/transformers/training.html#fine-tuning-in-pytorch-with-the-trainer-api) for training and evaluating the model.\n",
        "\n",
        "Even in this case, evaluate the model using ROUGE-2 precision, recall and f1-score. At this time, you may want to use [metrics python library](https://huggingface.co/metrics) to set the [`compute_metrics`](https://huggingface.co/transformers/main_classes/trainer.html#id1) parameter in Trainer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PELrns0Xo1r9"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}