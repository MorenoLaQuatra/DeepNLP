{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practice 4 - NER and Intent Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnykot1/7kDiSBh2rCcgxR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MorenoLaQuatra/DeepNLP/blob/main/practices/P4/Practice_4_NER_and_Intent_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrHLvIkbUsjZ"
      },
      "source": [
        "#**Deep Natural Language Processing @ PoliTO**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Teaching Assistant:** Moreno La Quatra\n",
        "\n",
        "**Practice 3:** Named Entities Recognition & Intent Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GQde2M-U4KV"
      },
      "source": [
        "## Named Entities Recognition\n",
        "\n",
        "Named-entity recognition (NER) is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into pre-defined categories such as person names, organizations, locations, medical codes, time expressions, quantities, monetary values, percentages, etc.\n",
        "\n",
        "![https://miro.medium.com/max/875/0*mlwDqNm7DFc_4maP.jpeg](https://miro.medium.com/max/875/0*mlwDqNm7DFc_4maP.jpeg)   \n",
        "\n",
        "Text domain is **crucial** while recognizing entities (political, medical, food...)\n",
        "\n",
        "In this practice you will:\n",
        "- Experiment with pre-trained models to extract entities from text\n",
        "- "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VXjktGnWUTm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9elJruvpWAQ_"
      },
      "source": [
        "### **Question 1: data preparation**\n",
        "\n",
        "The data collection is available [here](https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P4/NER/wikigold.conll.txt). \n",
        "This dataset was presented in [1][2] and consists of a set of manually annotated Wikipedia text. The data already in [CONLL](https://simpletransformers.ai/docs/ner-data-formats/#text-file-in-conll-format) format. Please read carefully before proceeding with data parsing.\n",
        "\n",
        "You need to extract clean sentences (no annotation) and, for each sentence, text associated to each entity:     \n",
        "- `sentences`: list of sentences\n",
        "- `annotations`: list of list of entities (both string and class information). E.g., `[[('010', 'MISC'), ('Japanese', 'MISC'), ('The Mad Capsule Markets', 'ORG')], [('Osc-Dis', 'MISC'), ('Introduction 010', 'MISC'), ('Come', 'MISC')], ...]`. You can remove I- prefix because the data collection does not actually cotains valuable prefixes.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "[1] Balasuriya, Dominic, et al. \"Named entity recognition in wikipedia.\"\n",
        "    Proceedings of the 2009 Workshop on The People's Web Meets NLP: Collaboratively Constructed Semantic Resources. Association for Computational Linguistics, 2009.\n",
        "\n",
        "[2] Nothman, Joel, et al. \"Learning multilingual named entity recognition\n",
        "    from Wikipedia.\" Artificial Intelligence 194 (2013): 151-175 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeGD-RtlV_0k"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P4/NER/wikigold.conll.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YK19r9la4jUd"
      },
      "source": [
        "def split_text_label(filename):\n",
        "    f = open(filename)\n",
        "    split_labeled_text = []\n",
        "    sentence = []\n",
        "    for line in f:\n",
        "        if len(line)==0 or line.startswith('-DOCSTART') or line[0]==\"\\n\":\n",
        "             if len(sentence) > 0:\n",
        "                 split_labeled_text.append(sentence)\n",
        "                 sentence = []\n",
        "             continue\n",
        "        splits = line.split(' ')\n",
        "        sentence.append([splits[0],splits[-1].rstrip(\"\\n\")])\n",
        "    if len(sentence) > 0:\n",
        "        split_labeled_text.append(sentence)\n",
        "        sentence = []\n",
        "    return split_labeled_text\n",
        "sentences_with_labels = split_text_label(\"wikigold.conll.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmIad5_ZUg6X"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY3VJcC9Bvnf"
      },
      "source": [
        "### **Question 2: inference with spacy for entity recognition**\n",
        "\n",
        "Spacy models comes with built-in NER models. Instantiate a [spacy model](https://spacy.io/usage/models) for the english language and get, for each sentence in the data collection, its named entities extracted from the model.\n",
        "\n",
        "Given that, the provided data collection only contains a subset of spacy labels map all the classes not available in the data collection to the `MISC` class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXMAjNvaIoj5"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mf0NzZzjPheL"
      },
      "source": [
        "### **Question 3: compute metrics for evaluating NER**\n",
        "\n",
        "Use [eval4ner](https://github.com/cyk1337/eval4ner) to evaluate the spacy model for NER on the parsed dataset.\n",
        "\n",
        "**Note**: please use `pip install git+https://github.com/MorenoLaQuatra/eval4ner` to use a fixed version of the library. Before passing the parameter to the evaluation function, create a deepcopy of each variable:\n",
        "\n",
        "The issue has been already reported to the original author."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACNK6UU98VZr"
      },
      "source": [
        "! pip install git+https://github.com/MorenoLaQuatra/eval4ner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlJM3PVa8SGS"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC19UMUZdJxc"
      },
      "source": [
        "### **Question 4: inference with transformers pipeline**\n",
        "\n",
        "Transformer-based models can be fine-tuned for token-level classification. The most relevant task in this class is NER. Use [transformers pipelines](https://huggingface.co/transformers/master/main_classes/pipelines.html#transformers.TokenClassificationPipeline) to recognize entities in the previous data collection. \n",
        "\n",
        "Evaluate the model using the same procedure of Q3.\n",
        "\n",
        "**Note:** the output of the pipeline differs with respect to spacy. Please be sure to process data correctly before running evaluation.\n",
        "\n",
        "**Note 2:** `ignore_labels` parameter could be useful to correctly parse entities.\n",
        "\n",
        "**Note 3:** `##` symbol is used when a token is a continuation of a previous one (Poli + ##TO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6pQuOdTZZVo"
      },
      "source": [
        "%%capture\n",
        "! pip install datasets transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8I-9jTBI_5F"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIrJbaVgi_ja"
      },
      "source": [
        "## Intent Detection\n",
        "\n",
        "In data mining, intention mining or intent mining is the problem of determining a user's intention from logs of his/her behavior in interaction with a computer system, such as in search engines. Intent Detection is the identification and categorization of what a user online intended or wanted to find when they type or speak with a conversational agent (or a search engine).\n",
        "\n",
        "![https://d33wubrfki0l68.cloudfront.net/32e2326762c75a0357ab1ae1976a60d4bbce724b/f4ac0/static/a5878ba6b0e4e77163dc07d07ecf2291/2b6c7/intent-classification-normal.png](https://d33wubrfki0l68.cloudfront.net/32e2326762c75a0357ab1ae1976a60d4bbce724b/f4ac0/static/a5878ba6b0e4e77163dc07d07ecf2291/2b6c7/intent-classification-normal.png)\n",
        "\n",
        "Data source (ATIS dataset): https://github.com/yvchen/JointSLU ; https://www.kaggle.com/siddhadev/atis-dataset-clean/home\n",
        "\n",
        "Use provided train/dev/test split accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L6-2ABir0yS"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P4/IntentDetection/atis.train.csv\n",
        "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P4/IntentDetection/atis.dev.csv\n",
        "!wget https://raw.githubusercontent.com/MorenoLaQuatra/DeepNLP/main/practices/P4/IntentDetection/atis.test.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14nJxxjTj8Q9"
      },
      "source": [
        "### **Question 5: two-step classification model**\n",
        "\n",
        "Train a classification model to identify the intent from sentence text. The model should leverage on pretrained BERT model to generate features for each sentence (No-finetuning).\n",
        "\n",
        "![https://github.com/MorenoLaQuatra/DeepNLP/blob/main/practices/P4/IntentDetection/no_finetuning.png?raw=true](https://github.com/MorenoLaQuatra/DeepNLP/blob/main/practices/P4/IntentDetection/no_finetuning.png?raw=true)\n",
        "\n",
        "\n",
        "Assess the performance of the generated model by using the **classification accuracy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STJSjSovq46n"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1xrNtQTq5WW"
      },
      "source": [
        "### **Question 6: finetuning end-to-end classification model**\n",
        "\n",
        "Train a new BERT model for the task of [sequence classification](https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification) (include BERT fine-tuning).  \n",
        "\n",
        "![https://github.com/MorenoLaQuatra/DeepNLP/blob/main/practices/P4/IntentDetection/finetuning.png?raw=true](https://github.com/MorenoLaQuatra/DeepNLP/blob/main/practices/P4/IntentDetection/finetuning.png?raw=true)\n",
        "\n",
        "Assess the performance of the generated model by using the **classification accuracy**.\n",
        "\n",
        "Which model has better performance?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqlKATw5sJAY"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}